{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "be23ac21",
   "metadata": {},
   "source": [
    "## Wobbly Rosenbrock (parameter noise in 'a') : nominal vs. CVaR-optimized"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9a814829",
   "metadata": {},
   "outputs": [],
   "source": [
    "import argparse\n",
    "import numpy as np\n",
    "import casadi as ca\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "def rosenbrock(x, a, b):\n",
    "    x1, x2 = x[0], x[1]\n",
    "    return (a - x1) ** 2 + b * (x2 - x1**2) ** 2\n",
    "\n",
    "\n",
    "def cvar_empirical(values, alpha: float):\n",
    "    \"\"\"\n",
    "    Empirical CVaR_alpha for a 1D array of loss values:\n",
    "      CVaR = mean of the upper (1-alpha) tail (>= VaR_alpha).\n",
    "    \"\"\"\n",
    "    values = np.asarray(values, dtype=float)\n",
    "    if not (0.0 < alpha < 1.0):\n",
    "        raise ValueError(\"alpha must be in (0,1)\")\n",
    "    if values.size == 0:\n",
    "        return np.nan\n",
    "    # Empirical VaR at level alpha\n",
    "    var_alpha = np.quantile(values, alpha)\n",
    "    tail = values[values >= var_alpha]\n",
    "    return float(tail.mean())\n",
    "\n",
    "\n",
    "def solve_nominal(a=1.0, b=100.0, lbx=(-2.0, -2.0), ubx=(2.0, 2.0), x0=(-1.2, 1.0)):\n",
    "    \"\"\"Minimize the deterministic Rosenbrock (no noise).\"\"\"\n",
    "    x = ca.MX.sym(\"x\", 2)  # type: ignore\n",
    "    f = rosenbrock(x, a, b)\n",
    "    nlp = {\"x\": x, \"f\": f}\n",
    "    solver = ca.nlpsol(\"nom\", \"ipopt\", nlp, {\"ipopt.print_level\": 0, \"print_time\": 0})\n",
    "    sol = solver(x0=x0, lbx=lbx, ubx=ubx)\n",
    "    x_nom = np.array(sol[\"x\"]).squeeze()\n",
    "    f_nom = float(sol[\"f\"])\n",
    "    return x_nom, f_nom\n",
    "\n",
    "\n",
    "def solve_cvar(\n",
    "    a=1.0,\n",
    "    b=100.0,\n",
    "    alpha=0.95,\n",
    "    Xi=None,\n",
    "    lbx=(-2.0, -2.0),\n",
    "    ubx=(2.0, 2.0),\n",
    "    x0=(-1.2, 1.0),\n",
    "):\n",
    "    \"\"\"\n",
    "    Solve CVaR minimization using RU formulation with parameter noise in 'a'.\n",
    "    Xi: array of shape (N,), zero-mean noise samples for 'a'.\n",
    "    \"\"\"\n",
    "    assert Xi is not None and Xi.ndim == 1\n",
    "    N = Xi.shape[0]\n",
    "\n",
    "    x = ca.MX.sym(\"x\", 2)  # type: ignore\n",
    "    t = ca.MX.sym(\"t\")  # type: ignore\n",
    "    u = ca.MX.sym(\"u\", N)  # type: ignore\n",
    "\n",
    "    g = []\n",
    "    for i in range(N):\n",
    "        a_eff = a + float(Xi[i])\n",
    "        fi = rosenbrock(x, a_eff, b)\n",
    "        g.append(u[i] - (fi - t))  # u_i >= f - t\n",
    "        g.append(u[i])  # u_i >= 0\n",
    "\n",
    "    obj = t + (1.0 / ((1.0 - alpha) * N)) * ca.sum1(u)\n",
    "\n",
    "    w = ca.vertcat(x, t, u)\n",
    "    lbg = [0.0] * len(g)\n",
    "    ubg = [ca.inf] * len(g)\n",
    "    lbw = list(lbx) + [-ca.inf] + [0.0] * N\n",
    "    ubw = list(ubx) + [ca.inf] + [ca.inf] * N\n",
    "    w0 = np.r_[x0, 1.0, np.zeros(N)]\n",
    "\n",
    "    nlp = {\"x\": w, \"f\": obj, \"g\": ca.vertcat(*g)}\n",
    "    solver = ca.nlpsol(\"cvar\", \"ipopt\", nlp, {\"ipopt.print_level\": 0, \"print_time\": 0})\n",
    "    sol = solver(x0=w0, lbx=lbw, ubx=ubw, lbg=lbg, ubg=ubg)\n",
    "    w_opt = np.array(sol[\"x\"]).squeeze()\n",
    "    x_cvar = w_opt[:2]\n",
    "    t_cvar = w_opt[2]\n",
    "    obj_cvar = float(sol[\"f\"])\n",
    "    return x_cvar, t_cvar, obj_cvar\n",
    "\n",
    "\n",
    "def evaluate_losses(xval, a, b, Xi):\n",
    "    \"\"\"Compute array of losses f(x, xi_a) for samples Xi.\"\"\"\n",
    "    vals = np.array(\n",
    "        [float((a + z - xval[0]) ** 2 + b * (xval[1] - xval[0] ** 2) ** 2) for z in Xi],\n",
    "        dtype=float,\n",
    "    )\n",
    "    return vals\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6df88492",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Set the parameters for the experiment\n",
    "\n",
    "a = 1.0\n",
    "b = 100.0\n",
    "alpha = 0.99\n",
    "N = 500\n",
    "sigma_a = 0.05\n",
    "M = 5000\n",
    "lbx, ubx = (-2.0, -2.0), (2.0, 2.0)\n",
    "x0 = (-1.2, -1.0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5349061e",
   "metadata": {},
   "source": [
    "#### Normal Distribution Pertubation\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1319e575",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "******************************************************************************\n",
      "This program contains Ipopt, a library for large-scale nonlinear optimization.\n",
      " Ipopt is released as open source code under the Eclipse Public License (EPL).\n",
      "         For more information visit https://github.com/coin-or/Ipopt\n",
      "******************************************************************************\n",
      "\n",
      "Nominal solution (deterministic Rosenbrock):\n",
      "  x_nom = [0.99999999 0.99999998]   f(x_nom; a,b) = 1.1434476595638644e-16\n",
      "  OOS (M=5000) mean=0.002417  CVaR@alpha=0.99 = 0.020196\n",
      "\n",
      "CVaR-optimized solution (train N=500, alpha=0.99):\n",
      "  x_cvar = [0.99655025 0.99311239]   t* = 0.016393286591070193   training objective (RU) = 0.019955877173173212\n",
      "  OOS (M=5000) mean=0.002417  CVaR@alpha=0.99 = 0.019941\n",
      "\n",
      "Comparison (OOS): CVaR@alpha=0.99\n",
      "  CVaR(x_cvar)  vs  CVaR(x_nom)  -->  0.019941  vs  0.020196\n",
      "  Mean(x_cvar)  vs  Mean(x_nom)  -->  0.002417  vs  0.002417\n"
     ]
    }
   ],
   "source": [
    "seed = 144\n",
    "dist = \"normal\"\n",
    "rng = np.random.default_rng(seed)\n",
    "Xi_train = rng.normal(0.0, sigma_a, size=N)\n",
    "Xi_eval = rng.normal(0.0, sigma_a, size=M)\n",
    "\n",
    "# Solve nominal problem (deterministic Rosenbrock with a=1.0, no noise)\n",
    "x_nom, f_nom = solve_nominal(a=a, b=b, lbx=lbx, ubx=ubx, x0=x0)\n",
    "losses_nom = evaluate_losses(x_nom, a, b, Xi_eval)\n",
    "cvar_nom = cvar_empirical(losses_nom, alpha)\n",
    "mean_nom = float(losses_nom.mean())\n",
    "print(\"Nominal solution (deterministic Rosenbrock):\")\n",
    "print(\"  x_nom =\", x_nom, \"  f(x_nom; a,b) =\", f_nom)\n",
    "print(\n",
    "    \"  OOS (M=%d) mean=%.6f  CVaR@alpha=%.2f = %.6f\"\n",
    "    % (M, mean_nom, alpha, cvar_nom)\n",
    ")\n",
    "print()\n",
    "\n",
    "## Solve CVaR problem with parameter noise in 'a'\n",
    "x_cvar, t_cvar, obj_cvar = solve_cvar(\n",
    "    a=a, b=b, alpha=alpha, Xi=Xi_train, lbx=lbx, ubx=ubx, x0=x0\n",
    ")\n",
    "losses_cvar = evaluate_losses(x_cvar, a, b, Xi_eval)\n",
    "cvar_cvar = cvar_empirical(losses_cvar, alpha)\n",
    "mean_cvar = float(losses_cvar.mean())\n",
    "print(\"CVaR-optimized solution (train N=%d, alpha=%.2f):\" % (N, alpha))\n",
    "print(\n",
    "    \"  x_cvar =\",\n",
    "    x_cvar,\n",
    "    \"  t* =\",\n",
    "    t_cvar,\n",
    "    \"  training objective (RU) =\",\n",
    "    obj_cvar,\n",
    ")\n",
    "print(\n",
    "    \"  OOS (M=%d) mean=%.6f  CVaR@alpha=%.2f = %.6f\"\n",
    "    % (M, mean_cvar, alpha, cvar_cvar)\n",
    ")\n",
    "print()\n",
    "\n",
    "## Compare nominal vs CVaR solutions\n",
    "print(\"Comparison (OOS): CVaR@alpha=%.2f\" % alpha)\n",
    "print(\n",
    "    \"  CVaR(x_cvar)  vs  CVaR(x_nom)  -->  %.6f  vs  %.6f\"\n",
    "    % (cvar_cvar, cvar_nom)\n",
    ")\n",
    "print(\n",
    "    \"  Mean(x_cvar)  vs  Mean(x_nom)  -->  %.6f  vs  %.6f\"\n",
    "    % (mean_cvar, mean_nom)\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "954cfbb1",
   "metadata": {},
   "source": [
    "### Students t distribution pertubation for heavy tails"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "28e49069",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Nominal solution (deterministic Rosenbrock):\n",
      "  x_nom = [0.99999999 0.99999998]   f(x_nom; a,b) = 1.1434476595638644e-16\n",
      "  OOS (M=5000) mean=0.007048  CVaR@alpha=0.99 = 0.237490\n",
      "\n",
      "CVaR-optimized solution (train N=500, alpha=0.99):\n",
      "  x_cvar = [0.95033942 0.90314501]   t* = 0.06865876555028139   training objective (RU) = 0.17558252015529915\n",
      "  OOS (M=5000) mean=0.009584  CVaR@alpha=0.99 = 0.234932\n",
      "\n",
      "Comparison (OOS): CVaR@alpha=0.99\n",
      "  CVaR(x_cvar)  vs  CVaR(x_nom)  -->  0.234932  vs  0.237490\n",
      "  Mean(x_cvar)  vs  Mean(x_nom)  -->  0.009584  vs  0.007048\n"
     ]
    }
   ],
   "source": [
    "seed = 340\n",
    "dist = \"students_t\"\n",
    "rng = np.random.default_rng(seed)\n",
    "Xi_train = rng.standard_t(df=3, size=N) * sigma_a\n",
    "Xi_eval = rng.standard_t(df=3, size=M) * sigma_a\n",
    "\n",
    "# Solve nominal problem (deterministic Rosenbrock with a=1.0, no noise)\n",
    "x_nom, f_nom = solve_nominal(a=a, b=b, lbx=lbx, ubx=ubx, x0=x0)\n",
    "losses_nom = evaluate_losses(x_nom, a, b, Xi_eval)\n",
    "cvar_nom = cvar_empirical(losses_nom, alpha)\n",
    "mean_nom = float(losses_nom.mean())\n",
    "print(\"Nominal solution (deterministic Rosenbrock):\")\n",
    "print(\"  x_nom =\", x_nom, \"  f(x_nom; a,b) =\", f_nom)\n",
    "print(\"  OOS (M=%d) mean=%.6f  CVaR@alpha=%.2f = %.6f\" % (M, mean_nom, alpha, cvar_nom))\n",
    "print()\n",
    "\n",
    "## Solve CVaR problem with parameter noise in 'a'\n",
    "x_cvar, t_cvar, obj_cvar = solve_cvar(\n",
    "    a=a, b=b, alpha=alpha, Xi=Xi_train, lbx=lbx, ubx=ubx, x0=x0\n",
    ")\n",
    "losses_cvar = evaluate_losses(x_cvar, a, b, Xi_eval)\n",
    "cvar_cvar = cvar_empirical(losses_cvar, alpha)\n",
    "mean_cvar = float(losses_cvar.mean())\n",
    "print(\"CVaR-optimized solution (train N=%d, alpha=%.2f):\" % (N, alpha))\n",
    "print(\n",
    "    \"  x_cvar =\",\n",
    "    x_cvar,\n",
    "    \"  t* =\",\n",
    "    t_cvar,\n",
    "    \"  training objective (RU) =\",\n",
    "    obj_cvar,\n",
    ")\n",
    "print(\n",
    "    \"  OOS (M=%d) mean=%.6f  CVaR@alpha=%.2f = %.6f\" % (M, mean_cvar, alpha, cvar_cvar)\n",
    ")\n",
    "print()\n",
    "\n",
    "## Compare nominal vs CVaR solutions\n",
    "print(\"Comparison (OOS): CVaR@alpha=%.2f\" % alpha)\n",
    "print(\"  CVaR(x_cvar)  vs  CVaR(x_nom)  -->  %.6f  vs  %.6f\" % (cvar_cvar, cvar_nom))\n",
    "print(\"  Mean(x_cvar)  vs  Mean(x_nom)  -->  %.6f  vs  %.6f\" % (mean_cvar, mean_nom))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
